<!DOCTYPE html>
<html lang="zh-CN">

  
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta name="author" content="董沅鑫, yuanxin.me@gmail.com">
  
  
  
  <title>Kubernetes (K8S) | Shen Peng&#39;s Blog</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="kubernetes,kubernetes,docker,k8s,linux,">
  

  <script>
    console.log('\n%c Hexo-theme-bmw v4.0 ' + '%c 🎉 https://github.com/dongyuanxin/theme-bmw 🎉\n' + '\n%c View demo online ' + '%c 🔍 https://godbmw.com/ 🔍  \n' , 'color: #fadfa3; background: #030307; padding:3px 0;', '', 'color: #fadfa3; background: #030307; padding:3px 0;', '');
  </script>

  

  

  
    <link rel="icon" href="/images/favicon.ico">
    <link rel="apple-touch-icon" href="/images/touch-icon.png">
  

  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/icon/iconfont.css">
<link rel="stylesheet" href="/css/github-markdown.css">
<link rel="stylesheet" href="/css/highlight.css">

  <script src="/js/util.js"></script>
<script src="/js/valine.min.js"></script>

  

  
    <link href="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.css" rel="stylesheet">
    <script src="https://cdn.bootcss.com/aplayer/1.10.1/APlayer.min.js" async></script>
  

  
    <link href="https://cdn.bootcss.com/social-share.js/1.0.16/css/share.min.css" rel="stylesheet">
  
  
  <script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js" async></script>
  
  
    <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.0/dist/av-min.js"></script>
  

</head>

  <body>

    

    <div id="app">

      <div class="header-wrap">
  <header>
    <div class="site-brand">
      <div class="site-title">
        <a href="/">shenpeng1982.github.io</a>
      </div>
    </div>
    <nav class="site-navigation">
      <ul class="nav-menu">
      
        <li class="nav-item" data-path="/">
          
            <a href="/" target="_self">
              主页
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/archives/">
          
            <a href="/archives/" target="_self">
              归档
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/categories/">
          
            <a href="/categories/" target="_self">
              分类
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/tags/">
          
            <a href="/tags/" target="_self">
              标签
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/friends/">
          
            <a href="/friends/" target="_self">
              友链
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/about/">
          
            <a href="/about/" target="_self">
              关于
            </a>
          
        </li>
      
        <li class="nav-item" data-path="">
          
            <a href="javascript:void(0);" v-else="">抓到我</a>
            <ul class="nav-menu--dropdown">
              
                <li>
                  <a href="https://github.com/shenpeng1982" target="_blank">
                    Github
                  </a>
                </li>
              
                <li>
                  <a href="https://www.douban.com/people/155688738/statuses" target="_blank">
                    知乎
                  </a>
                </li>
              
            </ul>
          
        </li>
      
      </ul>
    </nav>
    <i class="iconfont icon-menu"></i>
  </header>
</div>

<script>
  let links = document.querySelectorAll('.nav-item');
  for(let link of links){
    let childrenLink = link.querySelector('ul');
    link.addEventListener('mouseenter', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown active";
      }
    })
    link.addEventListener('mouseleave', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown";
      }
    })
  }
  let rootRealPath = getRealPath(window.location.pathname, true);
  for(let link of links) {
    let linkPath = link.getAttribute("data-path");
    if(linkPath && getRealPath(linkPath, true) === rootRealPath) {
      link.className = "nav-item hover";
    }
  }

  let iconMenu = document.querySelector("i.iconfont.icon-menu"),
    iconMenuClicked = false;
  let navDOM = document.querySelector("nav.site-navigation");
  iconMenu.addEventListener("click", () => {
    iconMenuClicked 
      ? navDOM.className = "site-navigation active"
      : navDOM.className = "site-navigation";
    iconMenuClicked = !iconMenuClicked;
  })
</script>

      








<div class="container post-index">

  

<div class="post">
  <h1 class="article-title">
    <span>Kubernetes (K8S)</span>
  </h1>
  <div class="article-top-meta">
    <span>
      发布 : 
      2020-02-15
    </span>
    
      <span>
        分类 : 
          <a href="/categories/kubernetes/">
            kubernetes
          </a>
      </span>
    
    
      <span>
        浏览 : <span class="article-timer" data-identity="Kubernetes-K8S"></span>
      </span>
    
  </div>

  

  <div class="article-content">
    <div class="markdown-body">
      <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Kubernetes这个词来自希腊语，意思是“舵手”或“领航员”，K8S是Kubernetes的缩写。</p>
<p>Kubernetes是google的容器编排工具Borg的开源版本，google在2014年将其开源，实际上Kubernetes也是应用全生命周期管理的工具。</p>
<p>通过Kubernetes，可以实现大规模容器集群的的自动化部署，自动扩缩容，维护等。</p>
<p>Kubernetes可以运行在物理机或虚拟机上。</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p><strong>可移植：</strong>支持公有云，私有云，混合云，多重云<br><strong>可扩展：</strong>模块化，插件化，可挂载，可组合<br><strong>自动化：</strong>自动部署，自动重启，自动复制，自动扩展/收缩</p>
<h2 id="应用生命周期管理步骤"><a href="#应用生命周期管理步骤" class="headerlink" title="应用生命周期管理步骤"></a>应用生命周期管理步骤</h2><h3 id="创建集群"><a href="#创建集群" class="headerlink" title="创建集群"></a>创建集群</h3><p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200217_001.jpg" alt="Alt text"></p>
<h3 id="部署应用"><a href="#部署应用" class="headerlink" title="部署应用"></a>部署应用</h3><p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200217_002.jpg" alt="Alt text"></p>
<h4 id="DEMO"><a href="#DEMO" class="headerlink" title="DEMO"></a>DEMO</h4><p><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/deploy-app/deploy-interactive/" target="_blank" rel="noopener">https://kubernetes.io/docs/tutorials/kubernetes-basics/deploy-app/deploy-interactive/</a></p>
<h3 id="查看应用"><a href="#查看应用" class="headerlink" title="查看应用"></a>查看应用</h3><p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200217_003.jpg" alt="Alt text"></p>
<h3 id="发布应用"><a href="#发布应用" class="headerlink" title="发布应用"></a>发布应用</h3><p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200217_004.jpg" alt="Alt text"></p>
<h3 id="扩展应用"><a href="#扩展应用" class="headerlink" title="扩展应用"></a>扩展应用</h3><p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200217_005.jpg" alt="Alt text"></p>
<h3 id="更新应用"><a href="#更新应用" class="headerlink" title="更新应用"></a>更新应用</h3><p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200217_006.jpg" alt="Alt text"></p>
<h2 id="为什么使用容器？"><a href="#为什么使用容器？" class="headerlink" title="为什么使用容器？"></a>为什么使用容器？</h2><p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200215_001.jpg" alt="Alt text"></p>
<p>传统方式，应用的运行，配置，管理，所有的生命周期和操作系统绑定，但这样做不利于应用的升级，回滚等。<br>当然也可以通过虚拟机来实现，但虚拟机非常重。<br>通过容器来部署应用，容器之间互相隔离，容器与底层硬件和操作系统是解耦的，占用资源少，部署快，每个应用被打包为一个容器镜像。</p>
<p>容器的优势：<br><strong>快速创建/部署应用：</strong>与虚拟机相比，容器镜像的创建更加容易。<br><strong>持续开发、集成和部署：</strong>提供可靠，频繁，简单的容器镜像创建/部署/回滚（容器镜像不可变）<br><strong>开发与运行相分离</strong><br><strong>开发，测试与生产环境一致</strong><br><strong>云平台或其它操作系统：</strong>容器镜像可以在RHEL，Ubuntu，CentOS等其它任何环境运行<br><strong>松耦合（Loosely coupled），分布式，弹性，微服务化：</strong>应用程序分为更小的、独立的部件<br><strong>资源隔离</strong><br><strong>资源利用：</strong>更高效</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h3><p>Cluster（集群）是计算、存储和网络资源的集合。<br>最简单的cluster可以只有一台主机，即是master也是node。</p>
<h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p>Master是Cluster的大脑，主要负责调度，即决定应用放在哪里运行。<br>master可以是物理机或虚拟机。</p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>为了高可用，可以有多个master</li>
</ul>
</blockquote>
<h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><p>Node的职责是运行容器应用，node由master管理，node负责监控并汇报容器的状态，并根据master的要求管理容器的生命周期。<br>node可以是物理机或虚拟机。</p>
<h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><p>Namespace可以将一个物理的cluster划分为多个逻辑的cluster，每个逻辑的cluster就是一个namespace。<br>不同的namespace里的资源是完全隔离的。<br>Kubernetes默认创建了两个namespace：</p>
<ul>
<li>default：创建资源时如果不指定namespace，默认放在这里</li>
<li>kube-system：K8S系统自己创建的资源，放在这里。</li>
</ul>
<h3 id="Pod-微服务"><a href="#Pod-微服务" class="headerlink" title="Pod (微服务)"></a>Pod (微服务)</h3><p>pod是一个逻辑概念，pod是Kubernetes中可创建/部署的最小单位（pod是kubernetes的原子调度单位，因此一个pod中的容器都应该在同一个节点上），每个pod是应用的一个实例</p>
<p>一个Pod封装了如下内容：</p>
<ul>
<li>一个应用容器（也可以有多个容器）</li>
<li>存储资源</li>
<li>独立的网络IP</li>
<li>管理控制容器运行方式的策略选项</li>
</ul>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>容器的本质是进程</li>
<li>pod类似于进程组</li>
</ul>
</blockquote>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>docker是pod中的常见运行时(runtime)，pod也支持其他的运行时</li>
<li>在单个pod中管理多个容器是相对高级的用法</li>
</ul>
</blockquote>
<p>Pod提供两种共享资源：网络，存储</p>
<p><strong>网络：</strong></p>
<ul>
<li>每个pod分配一个独立的IP</li>
<li>Pod中的每个容器共享网络命名空间（namespace），包括IP和端口</li>
<li>Pod内的容器可以使用localhost互相通信</li>
</ul>
<p><strong>存储：</strong></p>
<ul>
<li>Pod内所有的容器可以访问共享存储（shared volumes）</li>
<li>volumes还用于Pod中的数据持久化</li>
</ul>
<p>举例，如下图这个pod包含File Puller，Web Server两个容器，共享一个存储volume<br><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200223_001.jpg" alt="Alt text"></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>重启pod和重启容器不是一回事，pod只提供容器的运行环境并保持容器的运行状态，容器重启并不会导致pod的重启</li>
</ul>
</blockquote>
<p>上面说到pod是一个逻辑概念，pod实际上是共享了资源的一组容器，主要是共享了网络和存储。<br>pod在k8s中的实现需要有一个中间容器，叫做<code>infra</code>容器，<code>infra</code>容器永远被第一个创建，然后其他容器和<code>infra</code>容器关联在一起。</p>
<p><code>Infra</code>容器使用的是一个特殊的镜像<code>k8s.gcr.io/pause</code>，<code>pause</code>镜像由汇编编写，<code>Infra</code>容器永远处于暂停状态。</p>
<p>pod的生命周期和<code>Infra</code>容器的生命周期一致，因此重启pod和重启容器不是一回事。</p>
<p><img src="/2020/02/15/Kubernetes-K8S/./Image-020.jpg" alt="Alt text"></p>
<p>上图为k8s中的pause镜像</p>
<p>创建一个pod的yaml配置文件，如下</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      image:</span> <span class="attr">nginx:latest</span></span><br><span class="line"><span class="attr">      ports:</span></span><br><span class="line"><span class="attr">      - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<p>可以利用yaml语法工具，如 <a href="https://www.bejson.com/validators/yaml/" target="_blank" rel="noopener">Link</a>，用以保证生成的yaml文件格式正确</p>
<p>校验通过，格式正确<br><img src="/2020/02/15/Kubernetes-K8S/./Image-021.jpg" alt="Alt text"></p>
<p>校验未通过，spec的值有问题，不能出现<code>null</code><br><img src="/2020/02/15/Kubernetes-K8S/./Image-022.jpg" alt="Alt text"></p>
<p>创建pod</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f pod_nginx.yaml</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>建议在每个节点将镜像拉到本地，否则每次创建pod时找不到本地镜像都会尝试连线下载</li>
<li>默认情况下，master节点不会参与pod的部署</li>
</ul>
</blockquote>
<p>查看pod的状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn2 ~]# kubectl get pods</span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">nginx   1/1     Running   0          18m</span><br></pre></td></tr></table></figure>
<p>查看pod的更多的状态信息，包括IP，node等；如下IP：192.168.43.70是K8S内部网络IP，在每个节点上都可以ping通，IP的取值范围由初始化master节点时<code>kubeadm init</code>的<code>--pod-network-cidr</code>参数来定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn2 ~]# kubectl get pods -o wide</span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE   IP              NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx   1/1     Running   0          17m   192.168.43.70   ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
<p>获得pod的详细信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pods nginx</span><br></pre></td></tr></table></figure>
<p>最后通过curl测试一下nginx的是否运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn2 ~]# curl 192.168.43.70</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">    body &#123;</span><br><span class="line">        width: 35em;</span><br><span class="line">        margin: 0 auto;</span><br><span class="line">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br><span class="line">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span><br><span class="line">working. Further configuration is required.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;For online documentation and support please refer to</span><br><span class="line">&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span><br><span class="line">Commercial support is available at</span><br><span class="line">&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>现在在K8S的节点上可以访问内部网络的pod网段192.168.43.*，但外部还不可以</strong></p>
<p>删除pod</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn2 ~]# kubectl delete pod nginx</span><br><span class="line">pod &quot;nginx&quot; deleted</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl delete -f pod_nginx.yml </span><br><span class="line">pod &quot;nginx&quot; deleted</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>pod一般不会直接使用，而是通过deployment来管理使用</li>
</ul>
</blockquote>
<h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><p>Kubernetes可以通过controller创建和管理pod，提供副本管理、滚动升级、集群级别的自愈能力。简单的说就是，有几个副本，在什么样的node上运行。</p>
<p>pod的生命周期管理：当pod被创建后，会被kubernetes调度到node上，直到pod的进程终止、被删除、因为缺少资源被驱逐、node出现故障</p>
<p><strong>Pod模板：</strong><br>控制器（controller）通过模板来创建pod，对模板的修改不会影响已创建的pod</p>
<p>根据作用的不同，有多种controller</p>
<h4 id="ReplicaSet"><a href="#ReplicaSet" class="headerlink" title="ReplicaSet"></a>ReplicaSet</h4><p>用来实现pod的多副本管理，来实现pod的高可用。因此即使只有一个pod副本，也应该用replicaset来管理。比如pod挂了，自动在合适的节点上启动一个pod。pod副本的数量不够了，自动增加一个pod。</p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>上一代的ReplicationController已经不推荐使用</li>
<li>ReplicaSet包含ReplicationController的所有功能，主要区别是：</li>
</ul>
<ol>
<li>ReplicationController只支持基于等式的选择器(selector)，例如selector（env=dev或environment!=qa）</li>
<li>ReplicaSet还支持基于集合的选择器(selector)，例如selector（version in (v1.0, v2.0)）</li>
</ol>
</blockquote>
<p>如下创建一个replicaset的yaml配置文件replicaset_nginx.yml<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></p>
<p>创建replicaset</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f replicaset_nginx.yml</span><br></pre></td></tr></table></figure>
<p>查看创建的replicaset<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl get rs</span><br><span class="line">NAME    DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx   3         3         3       13m</span><br><span class="line">[root@ol75k8sn1 ~]# kubectl get rs -o wide</span><br><span class="line">NAME    DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR</span><br><span class="line">nginx   3         3         3       13m   nginx        nginx    tier=frontend</span><br></pre></td></tr></table></figure></p>
<p>查看pods</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl get pods -o wide</span><br><span class="line">NAME          READY   STATUS    RESTARTS   AGE   IP                NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-9726z   1/1     Running   0          16m   192.168.125.193   ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-984tc   1/1     Running   0          16m   192.168.43.72     ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-dpql6   1/1     Running   0          16m   192.168.43.71     ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
<p>删除一个pod<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl delete pod nginx-984tc</span><br><span class="line">pod &quot;nginx-984tc&quot; deleted</span><br></pre></td></tr></table></figure></p>
<p>再次查看，发现立马又新建了一个pod<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl get pods -o wide</span><br><span class="line">NAME          READY   STATUS    RESTARTS   AGE   IP                NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-9726z   1/1     Running   0          19m   192.168.125.193   ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-dpql6   1/1     Running   0          19m   192.168.43.71     ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-szxjk   1/1     Running   0          15s   192.168.125.194   ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<p>收缩replicaset</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl scale rs nginx --replicas=2</span><br><span class="line">replicaset.apps/nginx scaled</span><br><span class="line">[root@ol75k8sn1 ~]# kubectl get pods -o wide</span><br><span class="line">NAME          READY   STATUS        RESTARTS   AGE    IP                NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-9726z   1/1     Running       0          25m    192.168.125.193   ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-dpql6   1/1     Running       0          25m    192.168.43.71     ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-szxjk   0/1     Terminating   0          6m4s   &lt;none&gt;            ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[root@ol75k8sn1 ~]# kubectl get pods -o wide</span><br><span class="line">NAME          READY   STATUS    RESTARTS   AGE   IP                NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-9726z   1/1     Running   0          25m   192.168.125.193   ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-dpql6   1/1     Running   0          25m   192.168.43.71     ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
<p>扩张replicaset</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl scale rs nginx --replicas=4</span><br><span class="line">replicaset.apps/nginx scaled</span><br><span class="line">[root@ol75k8sn1 ~]# kubectl get pods -o wide</span><br><span class="line">NAME          READY   STATUS              RESTARTS   AGE   IP                NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-6vvj7   0/1     ContainerCreating   0          2s    &lt;none&gt;            ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-8p66z   0/1     ContainerCreating   0          2s    &lt;none&gt;            ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-9726z   1/1     Running             0          26m   192.168.125.193   ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-dpql6   1/1     Running             0          26m   192.168.43.71     ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[root@ol75k8sn1 ~]# kubectl get pods -o wide</span><br><span class="line">NAME          READY   STATUS    RESTARTS   AGE   IP                NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">nginx-6vvj7   1/1     Running   0          7s    192.168.125.195   ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-8p66z   1/1     Running   0          7s    192.168.43.73     ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-9726z   1/1     Running   0          26m   192.168.125.193   ol75k8sn3   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-dpql6   1/1     Running   0          26m   192.168.43.71     ol75k8sn2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>replicaset一般也不会直接使用，而是通过deployment来管理使用</li>
<li>通过改变replicaset模板里面pod的镜像版本，可以实现滚动升级</li>
</ul>
</blockquote>
<h4 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h4><p>最常用的controller，用来部署pod，管理pod的副本也就是管理replicaset。</p>
<p>官方文档 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" target="_blank" rel="noopener">Link</a></p>
<p><img src="/2020/02/15/Kubernetes-K8S/./deployment.png" alt="Alt text"></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>当用deployment来管理replicaset的时候，就不要再手动管理replicaset</li>
</ul>
</blockquote>
<p>如下一个deployment的配置文件的例子<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">nginx:v1.17.10</span></span><br><span class="line"><span class="attr">        ports:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure></p>
<p>创建deployment<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl create -f deployment_nginx.yml </span><br><span class="line">deployment.apps/nginx-deployment created</span><br></pre></td></tr></table></figure></p>
<p>扩展<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment nginx-deployment --replicas=4</span><br></pre></td></tr></table></figure></p>
<p>用service将deployment暴露给外网访问，具体见service章节<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment nginx-deployment --type=NodePort --port=80 --target-port=80</span><br></pre></td></tr></table></figure></p>
<h4 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h4><p>每个node最多只能运行一个pod副本。</p>
<h4 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h4><p>用于保证pod的每个副本在整个生命周期中名称是不变的，而其他controller不提供这个功能。</p>
<h4 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h4><p>用于结束后就删除的pod。</p>
<h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><p>pod可以有多个副本，每个pod都有自己的IP，而pod会频繁的被销毁或创建，IP会发生变化，用IP来访问pod不现实。<br>Service定义了外界访问一组特定的pod的方式，service有自己的IP和端口，不管pod怎么变，service的IP和端口不变，Service为pod提供了负载均衡。</p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>和Oracle的Service的概念有些类似</li>
</ul>
</blockquote>
<p>service有ClusterIP、NodePort、LoadBalancer几种类型</p>
<h4 id="ClusterIP"><a href="#ClusterIP" class="headerlink" title="ClusterIP"></a>ClusterIP</h4><p>通过<code>kubectl expose</code>为<code>nginx-deployment</code>这个deployment创建<code>ClusterIP</code>类型的service<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl expose deployment nginx-deployment</span><br><span class="line">service/nginx-deployment exposed</span><br><span class="line">[root@ol75k8sn1 ~]# kubectl get svc </span><br><span class="line">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes         ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   28d</span><br><span class="line">nginx-deployment   ClusterIP   10.101.174.40   &lt;none&gt;        80/TCP    12s</span><br></pre></td></tr></table></figure></p>
<p>生成的service的IP是10.101.174.40，但这个IP只能用于K8S集群内部访问，也无法ping的通</p>
<h4 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h4><p>通过<code>kubectl expose</code>为<code>nginx-deployment</code>这个deployment创建<code>NodePort</code>类型的service<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment nginx-deployment --type=NodePort --port=80 --target-port=80</span><br></pre></td></tr></table></figure></p>
<p><code>--type=NodePort</code>指出创建的service类型是<code>NodePort</code><br><code>--port=80</code>是service对外暴露的端口<br><code>--target-port=80</code>是deployment的端口</p>
<p>K8S自动将本机（或者说本节点）的32291端口，映射到service的80端口；端口的范围在<code>30000</code>到<code>32767</code>之间<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl get svc </span><br><span class="line">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">kubernetes         ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        28d</span><br><span class="line">nginx-deployment   NodePort    10.99.119.252   &lt;none&gt;        80:32291/TCP   3s</span><br></pre></td></tr></table></figure></p>
<p>之后就可以用任意K8S节点IP加端口来访问pod</p>
<p>如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\1&gt;curl 192.168.1.81:32291</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">    body &#123;</span><br><span class="line">        width: 35em;</span><br><span class="line">        margin: 0 auto;</span><br><span class="line">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br><span class="line">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span><br><span class="line">working. Further configuration is required.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;For online documentation and support please refer to</span><br><span class="line">&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span><br><span class="line">Commercial support is available at</span><br><span class="line">&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h4><p>通过<code>kubectl expose</code>为<code>nginx-deployment</code>这个deployment创建<code>LoadBalancer</code>类型的service<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment nginx-deployment --type=LoadBalancer --port=80 --target-port=80</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>LoadBalance方式只能用于云K8S（如google的GCE，亚马逊的AWS，阿里云等），私有K8S无法使用，在私有K8S中创建LoadBalance类型的service，其<code>EXTERNAL-IP</code>状态会一直是<code>pending</code> ，也就是提示你一直获取不到<code>EXTERNAL-IP</code></li>
<li>云服务商会给LoadBalancer类型的service自动分配一个公网IP，并帮你做负载均衡</li>
</ul>
</blockquote>
<p>如下是在私有K8S上出错信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl expose deployment nginx-deployment --type=LoadBalancer --port=80 --target-port=80</span><br><span class="line">service/nginx-deployment exposed</span><br><span class="line">[root@ol75k8sn1 ~]# kubectl get svc </span><br><span class="line">NAME               TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">kubernetes         ClusterIP      10.96.0.1        &lt;none&gt;        443/TCP        28d</span><br><span class="line">nginx-deployment   LoadBalancer   10.102.236.210   &lt;pending&gt;     80:32338/TCP   25s</span><br></pre></td></tr></table></figure></p>
<h4 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h4><p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200525_001.jpg" alt="Alt text"></p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="/2020/02/15/Kubernetes-K8S/./1585907988406.png" alt="Alt text"></p>
<p><img src="/2020/02/15/Kubernetes-K8S/./1514877224307415.png" alt="Alt text"></p>
<h3 id="Master-Node"><a href="#Master-Node" class="headerlink" title="Master Node"></a>Master Node</h3><p><strong>etcd:</strong>保存整个集群的状态</p>
<p><strong>API server:</strong>API接口，提供了操作资源的唯一接口；<br>包括：</p>
<ul>
<li>授权</li>
<li>认证</li>
<li>访问控制</li>
<li>API注册和发现等</li>
</ul>
<p><strong>Control Manager:</strong>用于维护集群的状态<br>比如:</p>
<ul>
<li>故障检测</li>
<li>自动扩展</li>
<li>滚动更新</li>
</ul>
<p><strong>Scheduler:</strong>用于调度资源，比如将Pod调度到某个Node上</p>
<h3 id="Node-1"><a href="#Node-1" class="headerlink" title="Node"></a>Node</h3><p><strong>Kubelet:</strong>用于管理容器的生命周期，同时也负责管理网络（CNI）和Volume存储（CVI）</p>
<p><strong>Container Runtime:</strong>负责镜像的管理，以及容器和Pod的真正的运行</p>
<p><strong>Proxy:</strong>为service提供cluster内部的服务发现和负载均衡</p>
<h3 id="Add-on-TBD"><a href="#Add-on-TBD" class="headerlink" title="Add-on (TBD)"></a>Add-on (TBD)</h3><h2 id="Docker基础-（TBD）"><a href="#Docker基础-（TBD）" class="headerlink" title="Docker基础 （TBD）"></a>Docker基础 （TBD）</h2><h3 id="导入导出image"><a href="#导入导出image" class="headerlink" title="导入导出image"></a>导入导出image</h3><p>从本地repository中导出image为压缩包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker save -o superset.tar amancevice/superset:latest</span><br></pre></td></tr></table></figure></p>
<p>导入到本地repository<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker load -i superset.tar</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>注意:</strong></p>
<ul>
<li>也可以用<code>docker export</code>和<code>docker import</code></li>
<li><code>save/load</code>是从image本身导出</li>
<li><code>export/import</code>是从container中导出，因此会带上用户在原始镜像基础上的修改</li>
</ul>
</blockquote>
<h3 id="修改image的tag"><a href="#修改image的tag" class="headerlink" title="修改image的tag"></a>修改image的tag</h3><p>有的时候我们拉下来的镜像是默认latest这个tag，不方便我们管理版本</p>
<p>用<code>docker inspect</code>命令侦测到镜像里的<code>VERSION</code>信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# docker inspect mysql|grep VERSION</span><br><span class="line">                &quot;GOSU_VERSION=1.12&quot;,</span><br><span class="line">                &quot;MYSQL_VERSION=8.0.20-1debian10&quot;</span><br><span class="line">                &quot;GOSU_VERSION=1.12&quot;,</span><br><span class="line">                &quot;MYSQL_VERSION=8.0.20-1debian10&quot;</span><br></pre></td></tr></table></figure></p>
<p>使用<code>docker tag</code>命令修改镜像的tag，格式为<code>镜像名:版本tag</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# docker tag mysql mysql:v8.0.20-1debian10</span><br></pre></td></tr></table></figure></p>
<p>改完后发现有两个同名，同image id，但tag不同的镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# docker images</span><br><span class="line">REPOSITORY                                                        TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">mysql                                                             latest              94dff5fab37f        5 days ago          541MB</span><br><span class="line">mysql                                                             v8.0.20-1debian10   94dff5fab37f        5 days ago          541MB</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>删掉tag为latest那个镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# docker rmi mysql:latest</span><br><span class="line">Untagged: mysql:latest</span><br></pre></td></tr></table></figure></p>
<h2 id="Kubernetes安装"><a href="#Kubernetes安装" class="headerlink" title="Kubernetes安装"></a>Kubernetes安装</h2><p>Kubernetes的安装有好3种方式：通过minikube，kubeadm，通过二进制安装包手动安装<br>minikube用来部署单节点集群，主要用于测试<br>kubeadm是自动部署工具<br>建议初学者首次安装使用安装包手动安装一次，kubeadm自动部署隐藏了很多细节，不利于初学者理解</p>
<h3 id="通过minikube部署测试环境"><a href="#通过minikube部署测试环境" class="headerlink" title="通过minikube部署测试环境"></a>通过minikube部署测试环境</h3><p>为了简化安装，这里我们会用到<code>minikube</code><br>从kubernetes 1.3版本开始，kubernetes提供一个叫做minikube的测试工具，minikube可以很方便的在本机创建kubernetes的单节点集群<br>minikube的github链接 <a href="https://github.com/kubernetes/minikube" target="_blank" rel="noopener">Link</a></p>
<h4 id="安装kubectl"><a href="#安装kubectl" class="headerlink" title="安装kubectl"></a>安装kubectl</h4><p>下载<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl</span><br></pre></td></tr></table></figure></p>
<p>赋权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x ./kubectl</span><br></pre></td></tr></table></figure>
<p>挪到<code>/usr/local/bin</code> 下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv ./kubectl /usr/<span class="built_in">local</span>/bin/kubectl</span><br></pre></td></tr></table></figure></p>
<p>查看安装的<code>kubectl</code>的版本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl version</span><br></pre></td></tr></table></figure></p>
<h4 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h4><p>通过yum安装容器运行时docker</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker</span><br></pre></td></tr></table></figure>
<p>设置docker的镜像仓库为阿里云镜像服务器<br> bash<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/docker/daemon.json</span><br></pre></td></tr></table></figure></p>
<p>其内容为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [<span class="string">"https://xxxxxxxx.mirror.aliyuncs.com"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中<code>https://xxxxxxxx.mirror.aliyuncs.com</code>为你通过阿里云获得的专属容器镜像加速地址</p>
<p>重启docker使配置生效<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></p>
<p>测试一下速度，尝试pull一个mysql镜像，非常快<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@ol77-k8s bin]<span class="comment"># docker pull mysql</span></span><br><span class="line">Using default tag: latest</span><br><span class="line">Trying to pull repository docker.io/library/mysql ... </span><br><span class="line">latest: Pulling from docker.io/library/mysql</span><br><span class="line">6d28e14ab8c8: Pull complete </span><br><span class="line">dda15103a86a: Pull complete </span><br><span class="line">55971d75ab8c: Pull complete </span><br><span class="line">f1d4ea32020b: Pull complete </span><br><span class="line">61420072af91: Pull complete </span><br><span class="line">05c10e6ccca5: Pull complete </span><br><span class="line">7e0306b13322: Pull complete </span><br><span class="line">900b113c001e: Pull complete </span><br><span class="line">06cd07c30bf4: Pull complete </span><br><span class="line">df0d65aee5aa: Pull complete </span><br><span class="line">53eeb6e0335c: Pull complete </span><br><span class="line">6cf8f9563e97: Pull complete </span><br><span class="line">Digest: sha256:f91e704ffa9f19b9a267d9321550a0772a1b64902226d739d3527fd6edbe3dfe</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> docker.io/mysql:latest</span><br></pre></td></tr></table></figure></p>
<h5 id="例：通过docker运行mysql"><a href="#例：通过docker运行mysql" class="headerlink" title="例：通过docker运行mysql"></a>例：通过docker运行mysql</h5><p>查看镜像仓库里面的image</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker search mysql</span><br></pre></td></tr></table></figure>
<p>从镜像仓库拉取最新版的mysql</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull mysql</span><br></pre></td></tr></table></figure>
<p>或者拉取某个固定版本的mysql（例如tag为5.7）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull mysql:5.7</span><br></pre></td></tr></table></figure></p>
<p>查看本地可用的image</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure>
<p>初次运行tag为5.7的mysql镜像</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name demo-mysql-5.7 -p 3310:3306 -e MYSQL_ROOT_PASSWORD=123456 -itd docker.io/mysql:5.7</span><br></pre></td></tr></table></figure>
<p><code>--name demo-mysql-5.7</code>：给容器起个名字<br><code>-p 3310:3306</code>：将本机端口3310映射到容器的端口3306<br><code>-e MYSQL_ROOT_PASSWORD=123456</code>：设置mysql的root密码<br><code>-itd</code>：i是交互式操作，t是一个终端，d指的是在后台运行</p>
<p>查看已启动的容器 (可以查到容器id，后面可以用名字也可以用容器id来操作)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a</span><br></pre></td></tr></table></figure>
<p>停止某运行的容器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop demo-mysql-5.7</span><br></pre></td></tr></table></figure>
<p>或<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker kill demo-mysql-5.7</span><br></pre></td></tr></table></figure></p>
<p>重新启动容器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker start demo-mysql-5.7</span><br></pre></td></tr></table></figure></p>
<p>交互式连接到docker的bash命令行（从而可以在docker内部执行命令）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it demo-mysql-5.7 bash</span><br></pre></td></tr></table></figure>
<p>连接到mysql（注意这里用<code>-P</code>指定的端口是外部端口，它会按照之前的设置被转换为docker内部的端口）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@2378f53e2bf7:/# mysql -P 3310 -u root -p</span><br></pre></td></tr></table></figure>
<p>连上mysql之后简单做一个查询</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select version();</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| version() |</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| 5.7.29    |</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>查看mysql的状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; status</span><br><span class="line">--------------</span><br><span class="line">mysql  Ver 14.14 Distrib 5.7.29, for Linux (x86_64) using  EditLine wrapper</span><br><span class="line"></span><br><span class="line">Connection id:		2</span><br><span class="line">Current database:	</span><br><span class="line">Current user:		root@localhost</span><br><span class="line">SSL:			Not in use</span><br><span class="line">Current pager:		stdout</span><br><span class="line">Using outfile:		&apos;&apos;</span><br><span class="line">Using delimiter:	;</span><br><span class="line">Server version:		5.7.29 MySQL Community Server (GPL)</span><br><span class="line">Protocol version:	10</span><br><span class="line">Connection:		Localhost via UNIX socket</span><br><span class="line">Server characterset:	latin1</span><br><span class="line">Db     characterset:	latin1</span><br><span class="line">Client characterset:	latin1</span><br><span class="line">Conn.  characterset:	latin1</span><br><span class="line">UNIX socket:		/var/run/mysqld/mysqld.sock</span><br><span class="line">Uptime:			15 min 7 sec</span><br></pre></td></tr></table></figure>
<p>删除容器（删除前需要先关闭容器）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm demo-mysql-5.7</span><br></pre></td></tr></table></figure></p>
<p>删除本地镜像（需要先删除运行的容器）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi demo-mysql-5.7</span><br></pre></td></tr></table></figure></p>
<p>查看容器的log，如下，查看最后100行log</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs --tail=100 CONTAINER_ID</span><br></pre></td></tr></table></figure>
<h4 id="安装minikube"><a href="#安装minikube" class="headerlink" title="安装minikube"></a>安装minikube</h4><p>下载和安装minikube<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \</span><br><span class="line">   &amp;&amp; sudo install minikube-linux-amd64 /usr/<span class="built_in">local</span>/bin/minikube</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>如果是运行在物理机上，需要在BIOS里面打开虚拟化<code>VT-x</code>或<code>AMD-v</code></li>
<li>如果是运行在<code>vmware</code>，由于不允许在虚拟层上再安装虚拟层，因此需要将<code>vm-driver</code>设为<code>none</code></li>
<li>如果是运行在<code>virtualbox</code>上，需要将<code>vm-driver</code>设为<code>virtualbox</code></li>
<li>如果是运行在<code>KVM</code>上，需要将<code>vm-driver</code>设为<code>kvm2</code></li>
<li>见文档 <a href="https://minikube.sigs.k8s.io/docs/start/linux/" target="_blank" rel="noopener">Link</a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">minikube config <span class="built_in">set</span> vm-driver none</span><br></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<p>默认minikube会分配2G内存，可以用下面的命令扩展到4G</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">minikube config <span class="built_in">set</span> memory 4096</span><br></pre></td></tr></table></figure>
<p>启动minikube，同样用<code>--registry-mirror</code>定义使用阿里<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">minikube start --image-mirror-country cn \</span><br><span class="line">    --iso-url=https://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/iso/minikube-v1.7.3.iso \</span><br><span class="line">    --registry-mirror=https://xxxxxxxx.mirror.aliyuncs.com</span><br></pre></td></tr></table></figure></p>
<p>整个启动过程如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@ol77-k8s bin]<span class="comment"># minikube start --image-mirror-country cn \</span></span><br><span class="line">&gt;     --iso-url=https://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/iso/minikube-v1.7.3.iso \</span><br><span class="line">&gt;     --registry-mirror=https://xxxxxxxx.mirror.aliyuncs.com</span><br><span class="line">* minikube v1.7.3 on Oracle 7.7</span><br><span class="line">* Using the none driver based on user configuration</span><br><span class="line">* Running on localhost (CPUs=2, Memory=7965MB, Disk=83526MB) ...</span><br><span class="line">* OS release is Oracle Linux Server 7.7</span><br><span class="line">! VM is unable to access k8s.gcr.io, you may need to configure a proxy or <span class="built_in">set</span> --image-repository</span><br><span class="line">* Preparing Kubernetes v1.17.3 on Docker 1.13.1 ...</span><br><span class="line">* Downloading kubectl v1.17.3</span><br><span class="line">* Downloading kubeadm v1.17.3</span><br><span class="line">* Downloading kubelet v1.17.3</span><br><span class="line">* Launching Kubernetes ... </span><br><span class="line">* Enabling addons: default-storageclass, storage-provisioner</span><br><span class="line">* Configuring <span class="built_in">local</span> host environment ...</span><br><span class="line">* </span><br><span class="line">! The <span class="string">'none'</span> driver provides limited isolation and may reduce system security and reliability.</span><br><span class="line">! For more information, see:</span><br><span class="line">  - https://minikube.sigs.k8s.io/docs/reference/drivers/none/</span><br><span class="line">* </span><br><span class="line">! kubectl and minikube configuration will be stored <span class="keyword">in</span> /root</span><br><span class="line">! To use kubectl or minikube commands as your own user, you may need to relocate them. For example, to overwrite your own settings, run:</span><br><span class="line">* </span><br><span class="line">  - sudo mv /root/.kube /root/.minikube <span class="variable">$HOME</span></span><br><span class="line">  - sudo chown -R <span class="variable">$USER</span> <span class="variable">$HOME</span>/.kube <span class="variable">$HOME</span>/.minikube</span><br><span class="line">* </span><br><span class="line">* This can also be <span class="keyword">done</span> automatically by setting the env var CHANGE_MINIKUBE_NONE_USER=<span class="literal">true</span></span><br><span class="line">* Waiting <span class="keyword">for</span> cluster to come online ...</span><br><span class="line">* Done! kubectl is now configured to use <span class="string">"minikube"</span></span><br><span class="line">* For best results, install kubectl: https://kubernetes.io/docs/tasks/tools/install-kubectl/</span><br></pre></td></tr></table></figure></p>
<p>之后就可以使用kubectl来操作kubernetes</p>
<p>打开kubernetes控制台</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ol77-k8s Downloads]<span class="comment"># minikube dashboard</span></span><br><span class="line">* Enabling dashboard ...</span><br><span class="line">* Verifying dashboard health ...</span><br><span class="line">* Launching proxy ...</span><br><span class="line">* Verifying proxy health ...</span><br><span class="line">http://127.0.0.1:34155/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200228_002.jpg" alt="Alt text"></p>
<h3 id="通过kubeadm部署集群"><a href="#通过kubeadm部署集群" class="headerlink" title="通过kubeadm部署集群"></a>通过kubeadm部署集群</h3><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><h5 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h5><p>Oracle Linux 7.x<br>Kubernetes 1.18</p>
<h5 id="配置节点环境"><a href="#配置节点环境" class="headerlink" title="配置节点环境"></a>配置节点环境</h5><p>系统要求如下：</p>
<ul>
<li>每个节点CPU至少2核，内存至少2G</li>
<li>hostname，MAC地址，product_uuid每个节点必须不同<br>hostname在Oracle Linux 7.x中可以通过<code>hostnamectl set-hostname</code>设置<br>product_uuidke可以通过<code>cat /sys/class/dmi/id/product_uuid</code>查看</li>
</ul>
<p>本次3个节点配置如下：<br>| IP      |     角色 |   CPU   |   内存   |   主机名   |<br>| :——– | :——: | :——: | :——: | :——: |<br>| 192.168.1.81 | master | 2核 | 4G | ol75k8sn1 |<br>| 192.168.1.82 | master | 2核 | 4G | ol75k8sn2 |<br>| 192.168.1.83 | master | 2核 | 4G | ol75k8sn3 |</p>
<p>在<code>/etc/hosts</code> 中添加3个节点的IP解析<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]<span class="comment"># cat /etc/hosts</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.1.81    ol75k8sn1</span><br><span class="line">192.168.1.82    ol75k8sn2</span><br><span class="line">192.168.1.83    ol75k8sn3</span><br></pre></td></tr></table></figure></p>
<h5 id="检查端口是否被占用"><a href="#检查端口是否被占用" class="headerlink" title="检查端口是否被占用"></a>检查端口是否被占用</h5><p>K8S默认端口如下图<br><img src="/2020/02/15/Kubernetes-K8S/./Pict_20200412_001.jpg" alt="Alt text"></p>
<p>可以通过两种方法查看端口占用<br><strong>方法一：</strong><br>查看本机所有端口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp</span><br></pre></td></tr></table></figure></p>
<p>查看特定端口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp | grep 8080</span><br></pre></td></tr></table></figure></p>
<p><strong>方法二：</strong><br>查看特定端口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -i:8080</span><br></pre></td></tr></table></figure></p>
<h5 id="禁用swap"><a href="#禁用swap" class="headerlink" title="禁用swap"></a>禁用swap</h5><p>swap会降低K8S的性能</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br></pre></td></tr></table></figure>
<p>注释掉<code>/etc/fstab</code>中的swap</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># /etc/fstab</span></span><br><span class="line"><span class="comment"># Created by anaconda on Mon Oct 21 06:40:15 2019</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Accessible filesystems, by reference, are maintained under '/dev/disk'</span></span><br><span class="line"><span class="comment"># See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">/dev/mapper/ol-root     /                       ext4    defaults        1 1</span><br><span class="line">UUID=6ed9c74f-dfba-4d20-9a75-16a6c1351b72 /boot                   xfs     defaults        0 0</span><br><span class="line"><span class="comment">#/dev/mapper/ol-swap     swap                    swap    defaults        0 0</span></span><br></pre></td></tr></table></figure>
<p>无需重启</p>
<h5 id="关闭selinux"><a href="#关闭selinux" class="headerlink" title="关闭selinux"></a>关闭selinux</h5><p>修改配置文件<code>/etc/selinux/config</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure></p>
<p>重启生效</p>
<h5 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>
<h5 id="载入必要的内核模块"><a href="#载入必要的内核模块" class="headerlink" title="载入必要的内核模块"></a>载入必要的内核模块</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">modprobe br_netfilter</span><br><span class="line">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class="line">#!/bin/bash</span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line">chmod 755 /etc/sysconfig/modules/ipvs.modules</span><br><span class="line">bash /etc/sysconfig/modules/ipvs.modules</span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span><br></pre></td></tr></table></figure>
<h5 id="配置国内yum源"><a href="#配置国内yum源" class="headerlink" title="配置国内yum源"></a>配置国内yum源</h5><p>添加阿里云的centos和epel源<br>见 <a href="https://shenpeng1982.github.io/2019/02/09/%E8%87%AA%E5%AE%9A%E4%B9%89YUM%E6%BA%90/" target="_blank" rel="noopener">GitPage Link</a></p>
<p>添加阿里云docker-ce的yum源<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></p>
<p>添加阿里云K8S的yum源</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>可以不做缓存<code>yum makecache</code>，在移动网络下，时间较长</li>
</ul>
</blockquote>
<h5 id="安装必须的软件包"><a href="#安装必须的软件包" class="headerlink" title="安装必须的软件包"></a>安装必须的软件包</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y screen conntrack ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget vim net-tools git</span><br></pre></td></tr></table></figure>
<h5 id="同步时间"><a href="#同步时间" class="headerlink" title="同步时间"></a>同步时间</h5><p>通过网络ntp服务器同步一下各个节点的系统时间<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ntpdate</span><br><span class="line">/usr/sbin/ntpdate ntp1.aliyun.com</span><br></pre></td></tr></table></figure></p>
<p>如果是在实体机安装，时钟分硬件时钟和系统时钟<br>通过<code>hwclock</code>查看硬件时钟</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@labk8sn1 ~]# hwclock</span><br><span class="line">Mon 25 May 2020 04:58:14 PM CST  -0.766585 seconds</span><br></pre></td></tr></table></figure>
<p>通过<code>date</code>查看系统时钟</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@labk8sn1 ~]# date</span><br><span class="line">Mon May 25 16:56:10 CST 2020</span><br></pre></td></tr></table></figure>
<p>将硬件时钟同步到系统时钟（以硬件时钟为准）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hwclock --hctosys</span><br></pre></td></tr></table></figure>
<p>将系统时钟同步到硬件时钟（以系统时钟为准）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hwclock --systohc</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>在本例中，首先通过网络同步了系统时间，所以现在需要将系统时间同步给硬件时间</li>
</ul>
</blockquote>
<h5 id="打开IP转发"><a href="#打开IP转发" class="headerlink" title="打开IP转发"></a>打开IP转发</h5><p>Linux默认<code>/proc/sys/net/ipv4/ip_forward</code>的值是0，也就是禁止转发</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>重启网络或重启服务器后效果不再</li>
</ul>
</blockquote>
<p>因此，将<code>echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward</code>写入<code>/etc/rc.d/rc.local</code>保证开机时执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/rc.d/rc.local</span><br><span class="line">echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure></p>
<h5 id="安装iptables"><a href="#安装iptables" class="headerlink" title="安装iptables"></a>安装iptables</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum -y install iptables-services</span><br><span class="line">systemctl start iptables</span><br><span class="line">systemctl enable iptables</span><br><span class="line">iptables -F</span><br><span class="line">service iptables save</span><br></pre></td></tr></table></figure>
<h5 id="修改默认iptables的网桥设置"><a href="#修改默认iptables的网桥设置" class="headerlink" title="修改默认iptables的网桥设置"></a>修改默认iptables的网桥设置</h5><p>首先保证内核模块<code>br_netfilter</code>已经加载</p>
<p>默认下面这几个参数的值都是0，意味着iptables不对网桥(bridge)数据进行处理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.bridge.bridge-nf-call-ip6tables = 0</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 0</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 0</span><br></pre></td></tr></table></figure>
<p>K8S要求这几个开关打开，iptables能看到和处理网桥数据<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-arptables = 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p>生效</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl --system</span><br></pre></td></tr></table></figure>
<p>也可以把这几个参数放在<code>/etc/sysctl.conf</code>里面，然后通过<code>/sbin/sysctl -p</code>生效</p>
<h5 id="日志持久化设置-（TBD）"><a href="#日志持久化设置-（TBD）" class="headerlink" title="日志持久化设置 （TBD）"></a>日志持久化设置 （TBD）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 设置 rsyslogd 和 systemd journald</span><br><span class="line">mkdir -p /var/log/journal # 持久化保存日志的目录</span><br><span class="line">mkdir -p /etc/systemd/journald.conf.d</span><br><span class="line">cat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF</span><br><span class="line">[Journal]</span><br><span class="line"># 持久化保存到磁盘</span><br><span class="line">Storage=persistent</span><br><span class="line"># 压缩历史日志</span><br><span class="line">Compress=yes</span><br><span class="line">SyncIntervalSec=5m</span><br><span class="line">RateLimitInterval=30s</span><br><span class="line">RateLimitBurst=1000</span><br><span class="line"># 最大占用空间10G</span><br><span class="line">SystemMaxUse=10G</span><br><span class="line"># 单日志文件最大200M</span><br><span class="line">SystemMaxFileSize=200M</span><br><span class="line"># 日志保存时间2周</span><br><span class="line">MaxRetentionSec=2week</span><br><span class="line"># 不将日志转发到syslog</span><br><span class="line">ForwardToSyslog=no</span><br><span class="line">EOF</span><br><span class="line">systemctl restart systemd-journald</span><br></pre></td></tr></table></figure>
<h4 id="安装容器运行时docker"><a href="#安装容器运行时docker" class="headerlink" title="安装容器运行时docker"></a>安装容器运行时docker</h4><p><code>docker-io</code>和<code>docker-engin</code>是早期版本，版本号是1.x，Oracle Linux 7.x，Redhat Enterprise Linux 7.x和Centos 7.x默认安装的是<code>docker-io</code>，最新版是1.13。<br><code>docker-ce</code>是社区版，Ubuntu默认安装的是<code>docker-ce</code>，最新版本是19.03<br><code>docker-ee</code>是企业版。</p>
<p>列出可以安装的版本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]<span class="comment"># yum list docker-ce</span></span><br><span class="line">Loaded plugins: langpacks, ulninfo</span><br><span class="line">Available Packages</span><br><span class="line">docker-ce.x86_64                                        3:19.03.8-3.el7                                        docker-ce-stable</span><br></pre></td></tr></table></figure></p>
<p>安装中如有如下报错信息，一般原因还是国内的源中包不全，一般添加阿里的centos和epel源之后都没有问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Error: Package: 3:docker-ce-19.03.8-3.el7.x86_64 (docker-ce-stable)</span><br><span class="line">           Requires: container-selinux &gt;= 2:2.74</span><br><span class="line">Error: Package: containerd.io-1.2.13-3.1.el7.x86_64 (docker-ce-stable)</span><br><span class="line">           Requires: container-selinux &gt;= 2:2.74</span><br></pre></td></tr></table></figure></p>
<p>如果还是报错，需要手动到<a href="https://pkgs.org/download" target="_blank" rel="noopener">https://pkgs.org/download</a>去下载安装</p>
<p>安装<code>docker-ce</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker-ce</span><br></pre></td></tr></table></figure>
<p>设置开机自启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure></p>
<p>启动docker<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure></p>
<h4 id="安装kubernetes集群"><a href="#安装kubernetes集群" class="headerlink" title="安装kubernetes集群"></a>安装kubernetes集群</h4><p>在所有节点安装kubelet，kubeadm和kubectl<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure></p>
<p>设置开机自启动kubelet<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>从这个时候开始，可以从node1克隆虚拟机为node2，node3以简化安装操作</li>
</ul>
</blockquote>
<p>kubelet的service现在启动会报错，这是正常情况，在下一节kubeadm init初始化之后，重启kubelet即可</p>
<h5 id="初始化主节点"><a href="#初始化主节点" class="headerlink" title="初始化主节点"></a>初始化主节点</h5><p>用下面的命令在主节点上初始化<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --image-repository=registry.aliyuncs.com/google_containers --kubernetes-version=v1.18.0 --pod-network-cidr=192.168.0.0/16</span><br></pre></td></tr></table></figure></p>
<ul>
<li>–image-repository：指定仓库地址，这里指定阿里云的仓库</li>
<li>–kubernetes-version：指定安装的kubernetes版本</li>
<li>–pod-network-cidr：指定pod的地址取值网段</li>
</ul>
<p>执行命令直到看到出现成功的信息</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.1.81:6443 --token jqd1u2.oeetwxopk4h18mjp \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:be840f62afba37facbdf3e9d9aa487c3b65bf7c06fc7dce65c32662c4a1cd41d</span><br></pre></td></tr></table></figure>
<p>根据上面提示，主节点上拷贝主节点的Kubernetes配置文件到用户目录下面，否则使用kubectl时会报错提示没有配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>在子结点上，在<code>kubeadm join</code>之前，不要拷贝生成<code>$HOME/.kube/config</code>，否则<code>kubectl join</code>会失败</li>
<li><code>kubeadm init</code>和<code>kubeadm join</code>之前，无需启动<code>kubelet</code></li>
</ul>
</blockquote>
<h5 id="安装网络插件"><a href="#安装网络插件" class="headerlink" title="安装网络插件"></a>安装网络插件</h5><p>Calico或flannel都可以</p>
<h6 id="配置Calico"><a href="#配置Calico" class="headerlink" title="配置Calico"></a>配置Calico</h6><p>Calico 是一款纯 Layer 3 的数据中心网络方案(不需要 Overlay 网络)，Calico 好处是他已与各种云原生平台有良好的整合，而 Calico 在每一个节点利用 Linux Kernel 实现高效的 vRouter 来负责数据的转发，而当数据中心复杂度增加时，可以用 BGP route reflector 来达成</p>
<p>官方教程 <a href="https://docs.projectcalico.org/getting-started/kubernetes/" target="_blank" rel="noopener">Link</a></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>Calico默认的IP段是<code>192.168.0.0/16</code>，如果和你的需求不一致，请在master节点通过<code>kubeadm init</code>初始化时通过<code>--pod-network-cidr</code>更改</li>
</ul>
</blockquote>
<p>应用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</span><br></pre></td></tr></table></figure></p>
<p>查看pod状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods --all-namespaces</span><br></pre></td></tr></table></figure></p>
<p>所有的pod状态都应该是<code>running</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl get pods --all-namespaces</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-kube-controllers-6fcbbfb6fb-hxrqh   1/1     Running   0          9d</span><br><span class="line">kube-system   calico-node-dk9gq                          1/1     Running   0          9d</span><br><span class="line">kube-system   calico-node-qw57c                          1/1     Running   0          21m</span><br><span class="line">kube-system   calico-node-slcqv                          1/1     Running   0          21m</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h6 id="配置Flannel（Calico和Flannel二选一）"><a href="#配置Flannel（Calico和Flannel二选一）" class="headerlink" title="配置Flannel（Calico和Flannel二选一）"></a>配置Flannel（Calico和Flannel二选一）</h6><p>flannel只需要在Node节点安装,Master节点无需安装</p>
<p>docker import flannel-v0.11.0-linux-amd64.tar quay.io/coreos/flannel:v0.11.0-arm64</p>
<p>kubectl apply -f kube-flannel.yml</p>
<h5 id="加入子节点"><a href="#加入子节点" class="headerlink" title="加入子节点"></a>加入子节点</h5><p>将其余两个节点加入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.1.81:6443 --token n556jt.wnkqsc536gzw8xvk \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:819a6cab80a0c617f972a9e04c71d1fbff92c383ce66d2e6a13f2106c7e960ad</span><br></pre></td></tr></table></figure></p>
<p>查看集群的状态，可以看到status和roles还不正常，这主要是因为还没有安装网络插件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl get nodes</span><br><span class="line">NAME        STATUS     ROLES    AGE     VERSION</span><br><span class="line">ol75k8sn1   NotReady   master   3h40m   v1.18.2</span><br><span class="line">ol75k8sn2   NotReady   &lt;none&gt;   7m48s   v1.18.2</span><br><span class="line">ol75k8sn3   NotReady   &lt;none&gt;   8m13s   v1.18.2</span><br></pre></td></tr></table></figure></p>
<h6 id="Toubleshooting：Token失效后如何加入子节点"><a href="#Toubleshooting：Token失效后如何加入子节点" class="headerlink" title="Toubleshooting：Token失效后如何加入子节点"></a>Toubleshooting：Token失效后如何加入子节点</h6><p>在1.8版之后，默认生成的 token 有效期只有 24 小时<br>在master节点上重新生成token<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]<span class="comment"># kubeadm token create</span></span><br><span class="line">W0505 18:33:08.907564   25966 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">fo2k3z.mpfllk3gextyuqoa</span><br></pre></td></tr></table></figure></p>
<p>获取 CA 证书 sha256 编码的 hash 值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &apos;s/^.* //&apos;</span><br><span class="line">be840f62afba37facbdf3e9d9aa487c3b65bf7c06fc7dce65c32662c4a1cd41d</span><br></pre></td></tr></table></figure></p>
<p>根据上面的结果，重新生成<code>kubeadm join</code>语句<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.1.81:6443 --token fo2k3z.mpfllk3gextyuqoa \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:be840f62afba37facbdf3e9d9aa487c3b65bf7c06fc7dce65c32662c4a1cd41d</span><br></pre></td></tr></table></figure></p>
<h4 id="扫尾排错工作"><a href="#扫尾排错工作" class="headerlink" title="扫尾排错工作"></a>扫尾排错工作</h4><h5 id="CASE-1"><a href="#CASE-1" class="headerlink" title="CASE 1"></a>CASE 1</h5><p>查看节点状态都是<code>Ready</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]# kubectl get nodes</span><br><span class="line">NAME        STATUS   ROLES    AGE     VERSION</span><br><span class="line">ol75k8sn1   Ready    master   9d      v1.18.2</span><br><span class="line">ol75k8sn2   Ready    &lt;none&gt;   6h22m   v1.18.2</span><br><span class="line">ol75k8sn3   Ready    &lt;none&gt;   6h22m   v1.18.2</span><br></pre></td></tr></table></figure></p>
<p>但kubelet虽然是<code>running</code>状态的log依然报错<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@ol75k8sn1 ~]<span class="comment"># systemctl status kubelet</span></span><br><span class="line">● kubelet.service - kubelet: The Kubernetes Node Agent</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /usr/lib/systemd/system/kubelet.service.d</span><br><span class="line">           └─10-kubeadm.conf</span><br><span class="line">   Active: active (running) since Wed 2020-05-06 01:10:12 CST; 17min ago</span><br><span class="line">     Docs: https://kubernetes.io/docs/</span><br><span class="line"> Main PID: 735 (kubelet)</span><br><span class="line">   Memory: 112.3M</span><br><span class="line">   CGroup: /system.slice/kubelet.service</span><br><span class="line">           └─735 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubern...</span><br><span class="line"></span><br><span class="line">May 06 01:26:27 ol75k8sn1 kubelet[735]: W0506 01:26:27.945469     735 qos_container_manager_linux.go:138] [Contain...: pids</span><br><span class="line">May 06 01:26:30 ol75k8sn1 kubelet[735]: E0506 01:26:30.167506     735 summary_sys_containers.go:47] Failed to get system...</span><br><span class="line">May 06 01:26:40 ol75k8sn1 kubelet[735]: E0506 01:26:40.298518     735 summary_sys_containers.go:47] Failed to get system...</span><br><span class="line">May 06 01:26:50 ol75k8sn1 kubelet[735]: E0506 01:26:50.327160     735 summary_sys_containers.go:47] Failed to get system...</span><br><span class="line">May 06 01:27:00 ol75k8sn1 kubelet[735]: E0506 01:27:00.347778     735 summary_sys_containers.go:47] Failed to get system...</span><br><span class="line">May 06 01:27:10 ol75k8sn1 kubelet[735]: E0506 01:27:10.368074     735 summary_sys_containers.go:47] Failed to get system...</span><br><span class="line">May 06 01:27:20 ol75k8sn1 kubelet[735]: E0506 01:27:20.388551     735 summary_sys_containers.go:47] Failed to get system...</span><br><span class="line">May 06 01:27:27 ol75k8sn1 kubelet[735]: E0506 01:27:27.946584     735 qos_container_manager_linux.go:328] [Contain...ration</span><br><span class="line">May 06 01:27:27 ol75k8sn1 kubelet[735]: W0506 01:27:27.946605     735 qos_container_manager_linux.go:138] [Contain...: pids</span><br><span class="line">May 06 01:27:30 ol75k8sn1 kubelet[735]: E0506 01:27:30.411942     735 summary_sys_containers.go:47] Failed to get system...</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show <span class="keyword">in</span> full.</span><br></pre></td></tr></table></figure></p>
<p>根据提示用<code>systemctl status kubelet -l</code>来查看完整的报错信息，如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">May 06 01:23:27 ol75k8sn1 kubelet[735]: W0506 01:23:27.935354     735 qos_container_manager_linux.go:138] [ContainerManager] Failed to reserve QoS requests: failed to <span class="built_in">set</span> supported cgroup subsystems <span class="keyword">for</span> cgroup [kubepods burstable]: failed to find subsystem mount <span class="keyword">for</span> required subsystem: pids</span><br><span class="line">May 06 01:23:29 ol75k8sn1 kubelet[735]: E0506 01:23:29.752777     735 summary_sys_containers.go:47] Failed to get system container stats <span class="keyword">for</span> <span class="string">"/system.slice/docker.service"</span>: failed to get cgroup stats <span class="keyword">for</span> <span class="string">"/system.slice/docker.service"</span>: failed to get container info <span class="keyword">for</span> <span class="string">"/system.slice/docker.service"</span>: unknown container <span class="string">"/system.slice/docker.service"</span></span><br></pre></td></tr></table></figure></p>
<p>在所有节点修改kubelet服务的配置文件<code>/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi  /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br></pre></td></tr></table></figure></p>
<p>在最后一行ExecStart最后添加<code>--feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false</code></p>
<p>修改前</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Note: This dropin only works with kubeadm and kubelet v1.11+</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;</span><br><span class="line"># This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically</span><br><span class="line">EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env</span><br><span class="line"># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use</span><br><span class="line"># the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/kubelet</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS</span><br></pre></td></tr></table></figure>
<p>修改后</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Note: This dropin only works with kubeadm and kubelet v1.11+</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;</span><br><span class="line"># This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically</span><br><span class="line">EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env</span><br><span class="line"># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use</span><br><span class="line"># the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/kubelet</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS --feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false</span><br></pre></td></tr></table></figure>
<p>重启所有节点</p>
<h5 id="CASE-2"><a href="#CASE-2" class="headerlink" title="CASE 2"></a>CASE 2</h5><p>经过CASE 1排错，主节点已经没有问题，但子节点依然报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">May 06 02:17:19 ol75k8sn3 kubelet[740]: E0506 02:17:19.298801     740 summary_sys_containers.go:47] Failed to get system container stats for &quot;/system.slice/docker.service&quot;: failed to get cgroup stats for &quot;/system.slice/docker.service&quot;: failed to get container info for &quot;/system.slice/docker.service&quot;: unknown container &quot;/system.slice/docker.service&quot;</span><br></pre></td></tr></table></figure>
<p>继续在所有子节点修改kubelet服务的配置文件<code>/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</code> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi  /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br></pre></td></tr></table></figure>
<p>添加环境参数<code>Environment=&quot;KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice&quot;</code></p>
<p>修改前<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Note: This dropin only works with kubeadm and kubelet v1.11+</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;</span><br><span class="line"># This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically</span><br><span class="line">EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env</span><br><span class="line"># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use</span><br><span class="line"># the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/kubelet</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS --feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false</span><br></pre></td></tr></table></figure></p>
<p>修改后</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Note: This dropin only works with kubeadm and kubelet v1.11+</span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;</span><br><span class="line">Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">Environment=&quot;KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice&quot;</span><br><span class="line"># This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically</span><br><span class="line">EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env</span><br><span class="line"># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use</span><br><span class="line"># the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/kubelet</span><br><span class="line">ExecStart=</span><br><span class="line">ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS --feature-gates SupportPodPidsLimit=false --feature-gates SupportNodePidsLimit=false</span><br></pre></td></tr></table></figure>
<p>重启子节点的kubelet服务</p>
<p>再次查看kubelet的log，确认没有Error信息</p>
<h4 id="Dashboard部署（TBD）"><a href="#Dashboard部署（TBD）" class="headerlink" title="Dashboard部署（TBD）"></a>Dashboard部署（TBD）</h4><h3 id="通过二进制安装包部署集群"><a href="#通过二进制安装包部署集群" class="headerlink" title="通过二进制安装包部署集群"></a>通过二进制安装包部署集群</h3><h3 id="安装Kubernetes集群过程中可能遇到的问题-TBD"><a href="#安装Kubernetes集群过程中可能遇到的问题-TBD" class="headerlink" title="安装Kubernetes集群过程中可能遇到的问题 (TBD)"></a>安装Kubernetes集群过程中可能遇到的问题 (TBD)</h3><h4 id="如何修改地址范围"><a href="#如何修改地址范围" class="headerlink" title="如何修改地址范围"></a>如何修改地址范围</h4><p>k8s 中如何修改 pod-network-cidr 地址范围<br>打开下面的2个配置，将 10.244.0.0/16 改为 192.168.0.0/16<br>1）kubectl -n kube-system edit cm kubeadm-config<br>2）vim /etc/kubernetes/manifests/kube-scheduler.yaml<br>通过 kubectl cluster-info dump | grep -m 1 cluster-cidr 命令可以检查配置是否生效</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>默认情况下，master节点不应该参与pod的调度，但可以通过设置改变</p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>让master节点参与pod调度有可能会因为master节点资源不足导致K8S集群不稳定</li>
</ul>
</blockquote>
<p>kubernetes是通过的taint（污点）来决定调度规则的</p>
<h2 id="存储卷"><a href="#存储卷" class="headerlink" title="存储卷"></a>存储卷</h2><h2 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h2><h3 id="1-强制删除pod"><a href="#1-强制删除pod" class="headerlink" title="1. 强制删除pod"></a>1. 强制删除pod</h3><p>一般删除pod都是通过<code>kubectl delete pod</code>来删的<br>有的时候，删除pod后一直是<code>Terminating</code>状态，无法继续，如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@labk8sn1 ~]# kubectl get pods --all-namespaces -o wide</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS        RESTARTS   AGE     IP                NODE       NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   coredns-7ff77c879f-s5jc5                   0/1     Terminating   0          38m     192.168.102.80    labk8sn2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<p>可以通过<code>kubectl delete pods &lt;pod&gt; --grace-period=0 --force</code>来强制删除<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete pods calico-kube-controllers-789f6df884-dvpk8 --grace-period=0 --force -n kube-system</span><br></pre></td></tr></table></figure></p>
<h3 id="2-重置kubernetes"><a href="#2-重置kubernetes" class="headerlink" title="2. 重置kubernetes"></a>2. 重置kubernetes</h3><p>有的时候安装失败，或网络插件有问题，或换IP，或者其他一些场景，需要重新<code>kubeadm init</code>和<code>kubeadm join</code>，这种情况下，运行以下命令重置kubenetes<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 重置kubeadm</span><br><span class="line"># 清空iptables规则</span><br><span class="line"># 重启</span><br><span class="line">kubeadm reset -f</span><br><span class="line">iptables -F &amp;&amp; iptables -t nat -F &amp;&amp; iptables -t mangle -F &amp;&amp; iptables -X</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></p>
<p>重启后需要删除之前kubeadm生成的配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf $HOME/.kube</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>重置后，再次<code>kubeadm init</code>或<code>kubeadm join</code>都无需联网</li>
</ul>
</blockquote>
<h3 id="3-端口占用"><a href="#3-端口占用" class="headerlink" title="3. 端口占用"></a>3. 端口占用</h3><p>重置之后，再次<code>kubeadm join</code>，报错如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ERROR Port-10250]: Port 10250 is in use</span><br></pre></td></tr></table></figure></p>
<p>用<code>lsof -i:10250</code>发现就是kubelet在占用</p>
<p>再次<code>kubeadm reset</code>并重启即可</p>
<h3 id="4-在reset之后需要清理旧配置文件"><a href="#4-在reset之后需要清理旧配置文件" class="headerlink" title="4. 在reset之后需要清理旧配置文件"></a>4. 在reset之后需要清理旧配置文件</h3><p>报错如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@labk8sn1 default]# kubectl get nodes</span><br><span class="line">Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of &quot;crypto/rsa: verification error&quot; while trying to verify candidate authority certificate &quot;kubernetes&quot;)</span><br></pre></td></tr></table></figure></p>
<p>这种情况一般出现在重置之后，由于没有删除旧的配置文件夹<code>$HOME/.kube</code>，导致报错</p>
<p>删除旧的配置文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf $HOME/.kube</span><br></pre></td></tr></table></figure></p>
<p>再按照<code>kubeadm init</code>提示信息里面重新拷贝一份新的即可</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<h3 id="5-cgroup-driver不匹配"><a href="#5-cgroup-driver不匹配" class="headerlink" title="5. cgroup driver不匹配"></a>5. cgroup driver不匹配</h3><p>在我们<code>kubeadm init</code>或<code>kubeadm join</code>运行时，会发现有如下提示信息，这不是个错误，只是报警<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>docker的cgroup driver和K8S的cgroup driver必须一致</li>
</ul>
</blockquote>
<p>这个报警信息的主要原因是docker的默认cgroup driver是<code>cgroupfs</code>，K8S会侦测到docker的cgroup driver，并将自己的cgroup driver设置为<code>cgroupfs</code>；但提示信息里面推荐用<code>systemd</code></p>
<p>但尝试换为<code>systemd</code>没有成功</p>
<p><strong>注意以下操作没有成功</strong></p>
<p>尝试把<code>cgroupfs</code>改为<code>systemd</code></p>
<p>修改docker</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">  &quot;storage-opts&quot;: [</span><br><span class="line">    &quot;overlay2.override_kernel_check=true&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/systemd/system/docker.service.d</span><br></pre></td></tr></table></figure>
<p>重启docker</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>
<p>修改K8S</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi  /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br></pre></td></tr></table></figure>
<p>修改参数如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Environment=&quot;KUBELET_CGROUP_ARGS=--cgroup-driver=systemd --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice&quot;</span><br></pre></td></tr></table></figure></p>
<p>重启kubelet<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>如果需要修改<code>systemd</code>，以上<code>systemd</code>替换为<code>cgroupfs</code>即可</li>
</ul>
</blockquote>
<h3 id="6-Calico-BIRD-is-not-ready-BGP-not-established"><a href="#6-Calico-BIRD-is-not-ready-BGP-not-established" class="headerlink" title="6. Calico BIRD is not ready: BGP not established"></a>6. Calico BIRD is not ready: BGP not established</h3><p>现象还包括某个calico-node状态一直不正常，保持在<code>0/1</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kube-system   calico-node-dpln6                          0/1     Running   0          26m</span><br></pre></td></tr></table></figure></p>
<p>这个问题主要是Calico自动匹配的网卡不对导致（比如服务器有多个网卡，Calico自动匹配第一个网卡，但这个网卡并不对），修改下载下来的配置文件calico.yaml</p>
<p>搜索<code>name: IP</code><br>在它上面加入2行，告知用到网卡是哪个，比如，我指定的是绑定网卡bond0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- name: IP_AUTODETECTION_METHOD</span><br><span class="line">  value: &quot;interface=bond&quot;</span><br></pre></td></tr></table></figure>
<p>保存后应用修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>实在解决不了只能重置，重置一般能解决问题，之前我就是不管怎么改都不行，重置后解决</li>
</ul>
</blockquote>
<h3 id="7-Orphaned-pod-found"><a href="#7-Orphaned-pod-found" class="headerlink" title="7. Orphaned pod found"></a>7. Orphaned pod found</h3><p>报错如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Jan 21 16:45:44 localhost kubelet[1277]: E0121 16:45:44.079748    1277 kubelet_volumes.go:128] Orphaned pod &quot;86d60ee9-9fae-11e8-8cfc-525400290b20&quot; found, but volume paths are still present on disk. : There were a total of 1 errors similar to this.  Turn up verbosity to see them.</span><br></pre></td></tr></table></figure></p>
<p>原因主要时删除pod后，K8S没有清理干净，还能找到残留的文件</p>
<p>根据提示信息，到<code>/var/lib/kubelet/pods/</code>下将于报错信息对应的一长串数字命名的文件夹删掉即可</p>
<h2 id="应用部署"><a href="#应用部署" class="headerlink" title="应用部署"></a>应用部署</h2><h3 id="Node-Red"><a href="#Node-Red" class="headerlink" title="Node-Red"></a>Node-Red</h3><h4 id="docker部署"><a href="#docker部署" class="headerlink" title="docker部署"></a>docker部署</h4><p>拉取最新的nodered 1.04的镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull nodered/node-red:1.0.4</span><br></pre></td></tr></table></figure></p>
<p>运行容器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -p 1880:1880 -v /data/nodered:/data -e TZ=Asia/Shanghai --name nodered -d nodered/node-red:1.0.4</span><br></pre></td></tr></table></figure></p>
<p><code>-p 1880:1880</code>将本机端口1880映射为容器端口1880<br><code>-v /data/nodered:/data</code>将本机目录/data/nodered映射为容器内目录/data，容器内的默认目录就是<code>/data</code><br><code>-e TZ=Asia/Shanghai</code>设置时区<br><code>--name nodered</code>生成的容器命名为nodered<br><code>-d nodered/node-red:1.0.4</code>部署的本地镜像是nodered/node-red:1.0.4</p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>在虚拟机上创建本地目录时，例如本例中是<code>/data/nodered</code>，需要将其读写权限设为<code>777</code>，否则报错</li>
</ul>
</blockquote>
<h4 id="K8S部署"><a href="#K8S部署" class="headerlink" title="K8S部署"></a>K8S部署</h4><p>创建名为<code>deployment_nodered.yml</code>的配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nodered-deployment</span><br><span class="line">  labels:</span><br><span class="line">    app: nodered</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nodered</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nodered</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nodered/node-red:1.0.4  </span><br><span class="line">        name: nodered</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 1880</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: nodered-volume-01</span><br><span class="line">          mountPath: /data</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nodered-volume-01</span><br><span class="line">          hostPath:</span><br><span class="line">              path: /data/nodered/nodered01</span><br></pre></td></tr></table></figure></p>
<p>节点上本机目录为<code>/data/nodered/nodered01</code>，赋予<code>777</code>权限</p>
<p>创建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f deployment_nodered.yml</span><br></pre></td></tr></table></figure>
<p>通过service暴露端口</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment nodered-deployment --type=NodePort --port=1880 --target-port=1880</span><br></pre></td></tr></table></figure>
<p>如下暴露出来的端口是30947<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@labk8sn1 ~]# kubectl get svc -o wide</span><br><span class="line">NAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE    SELECTOR</span><br><span class="line">kubernetes           ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP          2d3h   &lt;none&gt;</span><br><span class="line">nodered-deployment   NodePort    10.102.77.22   &lt;none&gt;        1880:30947/TCP   12s    app=nodered</span><br></pre></td></tr></table></figure></p>
<p>通过任意节点IP加如上端口访问</p>
<h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><h3 id="superset"><a href="#superset" class="headerlink" title="superset"></a>superset</h3><p>官方github <a href="https://github.com/amancevice/docker-superset" target="_blank" rel="noopener">Link</a></p>
<p>运行superset<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name superset -itd -p 8088:8088 -v /data/superset/config:/etc/superset -v /data/superset/sqllite:/var/lib/superset amancevice/superset</span><br></pre></td></tr></table></figure></p>
<p><code>-v</code>:挂载目录，对于superset来说，配置文件目录<code>/etc/superset</code>或者<code>/home/superset</code> 都可以，只要映射一个就行;本例中将本机的<code>/data/superset</code>映射为容器的<code>/home/superset</code>；数据文件目录在容器的<code>/var/lib/superset</code>下</p>
<blockquote>
<p><strong>注意：</strong></p>
<ul>
<li><code>-v</code>可以多次使用来挂载多个目录</li>
<li>本机目录需要777权限</li>
</ul>
</blockquote>
<p>初始化数据库，会提示创建admin user</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it superset superset-init</span><br></pre></td></tr></table></figure>
<p>之后就可以通过<code>http://IP:8088</code>的方式来打开superset的UI</p>
<p>容器如果需要版本升级，见github</p>
<h2 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h2><h2 id="私有K8S集群创建LoadBalance服务（TBD）"><a href="#私有K8S集群创建LoadBalance服务（TBD）" class="headerlink" title="私有K8S集群创建LoadBalance服务（TBD）"></a>私有K8S集群创建LoadBalance服务（TBD）</h2><p>通过metallb为私有的Kebernetes集群创建Load Balance服务<br>metallb Github <a href="https://github.com/metallb/metallb" target="_blank" rel="noopener">link</a><br>metallb会从你给定的IP池中选一个作为service的external IP给到deployment</p>
<h2 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h2><p><a href="http://docs.kubernetes.org.cn/227.html" target="_blank" rel="noopener">http://docs.kubernetes.org.cn/227.html</a></p>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><p>v1.0，2020.02.15~2020.05.31，初始版本</p>

    </div>
  </div>
  
    <div class="copy-right">
      <div class="markdown-body">
        <blockquote>
        
        
          本文作者 : Shen Peng <br>
        
        原文链接 : <a href="">http://yoursite.com/2020/02/15/Kubernetes-K8S/</a><br>
        版权声明 : 本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！
        </blockquote>
      </div>
    </div>
  
  
  
    <div class="social-share" style="margin-top: -2rem" data-wechat-qrcode-title="<p>微信扫一扫</p>" data-wechat-qrcode-helper="<p>微信右上角, 扫一扫分享</p>" data-sites="qzone, qq, weibo, wechat, douban, google, facebook, twitter">
  <span style="color: #6b7487; font-size: 1.4rem;">分享到: </span>
</div>
<script src="https://cdn.bootcss.com/social-share.js/1.0.16/js/social-share.min.js" async></script>
  

  
    <div id="reward">
  
    <p id="reward-meta">知识 & 情怀 | 二者兼得</p>
  
  <button id="reward-btn">
    
    <span>投食</span>
  </button>
  <div id="reward-qrcode">
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/wechat.png" alt="微信扫一扫, 向我投食">
        <p class="qrcode-meta">微信扫一扫, 向我投食</p>
      </div>
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/alipay.png" alt="支付宝扫一扫, 向我投食">
        <p class="qrcode-meta">支付宝扫一扫, 向我投食</p>
      </div>
    
  </div>

</div>

<script>
  (() => {
    let button = document.querySelector('#reward-btn'),
      qrcode = document.querySelector('#reward-qrcode'),
      display = false;
    
    button.addEventListener('click', () => {
      qrcode.style.display = display ? 'none' : 'block'
      display = !display
    }, false)
  })()
</script>
  

  <div class="article-footer">
    <div class="article-meta pull-left">
      <span>
        
          <i class="iconfont icon-06tags"></i>标签: 
          
          <span class="span--tag">
            <a href="/tags/kubernetes/">
              #kubernetes
            </a>
          </span>
          
          <span class="span--tag">
            <a href="/tags/docker/">
              #docker
            </a>
          </span>
          
          <span class="span--tag">
            <a href="/tags/k8s/">
              #k8s
            </a>
          </span>
          
          <span class="span--tag">
            <a href="/tags/linux/">
              #linux
            </a>
          </span>
          
        
      </span>
    </div>
    <div class="article-meta pull-right">
    </div>
  </div>
</div>


  <aside id="sidebar">
    <p id="sidebar-header"></p>
    <ol id="sidebar-toc"></ol>
  </aside>
  <script async>setTimeout(generateToc, 10);</script>


  <nav class="post-navigation">
    
      <div class="nav-pre">
        <i class="iconfont icon-prev"></i>
        上一篇:
        <a href="/2020/02/06/常用Linux命令对比/" target="_self">常用Linux命令对比</a>
      </div>
    
    
      <div class="nav-next">
        下一篇:
        <a href="/2020/03/24/LVM管理/" target="_self">LVM管理</a>
        <i class="iconfont icon-next"></i>
      </div>
    
  </nav>

  
    <a href="#comment" class="comment-anchor"></a>
<div class="comment-title"><i class="iconfont icon-footprint"></i> 留下足迹 <i class="iconfont icon-footprint"></i></div>
<div id="vcomments"></div>

<script defer>
  if( true ) {
    let path = getRealPath()
    new Valine({
      el: "#vcomments",
      appId: "3OKDIg4e0wo2F4MdSnk6pURw-gzGzoHsz",
      appKey: "HL7IxJ3hMAqxfnzCoBXPPdqL",
      notify: false,
      verify: false,
      avatar: "robohash",
      placeholder: "正确填写邮箱, 才能及时收到回复哦♪(^∇^*)",
      path
    });
  }
</script>
   

  
    <script defer>
const valineAPI = (() => {
  try {
    AV.init("3OKDIg4e0wo2F4MdSnk6pURw-gzGzoHsz", "HL7IxJ3hMAqxfnzCoBXPPdqL");
  } catch(error) {}
  const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
      query.equalTo("identity", identity);
      query.find().then(results => {
        resolve(results.length > 0);
      }, error => reject(error));
    })
  }

  const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
      let querys = [];
      for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
      }
      query = AV.Query.or.apply(null ,querys);
    } else {
      identity = identity || getRealPath();
      query = new AV.Query("Timer");
      query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
      query.find()
      .then(results => resolve(results))
      .catch(error => reject(error))
    })
  }

  const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let Todo = AV.Object.extend('Timer');
      let todo = new Todo();
      todo.set("times", 1);
      todo.set("identity", identity);
      todo.save().then(res => resolve(true), error => reject(error));
    })
  }

  const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let query = new AV.Query('Timer');
      query.equalTo("identity", identity);
      query.find().then(todos => {
        todos.forEach(todo => {
          todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
      }).then(todos => resolve(true), error => reject(error));
    })
  }

  return {
    isExist,
    _get,
    update,
    create
  }
})()

const calcAndWriteTimes = () => {
  let isPost = true;

  let timerAllDOM = document.querySelectorAll(".article-timer");

  if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
      if(exist) {
        return valineAPI.update(identity);
      }
      return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
  }

  let timerDOMCache = {};

  for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
      timerDOMCache[identity].dom.push(timerDOM);
    }else{
      timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
      };
    }
  }

  let identities = Object.keys(timerDOMCache);
  valineAPI._get(identities).then(results => {
    for(let result of results) {
      let {identity, times} = result.attributes;
      timerDOMCache[identity].times = times;
      timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
      if(timerDOMCache[identity].times){
        continue;
      }
      timerDOMCache[identity].dom.map(item => item.innerText = 1);
      valineAPI.create(identity);
    }
  }).catch(error => console.log(error.message))
}

if(true){
  calcAndWriteTimes();
}
</script>
   

</div>


      <footer>
  <p class="site-info">
    博客已萌萌哒运行<span id="time-to-now"></span><span class="my-face">(●'◡'●)ﾉ♥</span>
    <br>
    Theme - <a href="https://github.com/dongyuanxin/theme-bmw">BMW</a> | Made With 💗 | Powered by <a href="https://godbmw.com/">GodBMW</a>
    <br>
    
  </p>
</footer>



<script>
const timeToNowDOM = document.querySelector("#time-to-now");
const startTimestamp = new Date(2018, 1, 10).getTime();

const updateTimeStr = () => {
  let offset = parseInt(
      (new Date().getTime() - startTimestamp) / 1000,
      10
    ),
    day = Math.floor(offset / 86400),
    hour = Math.floor((offset % 86400) / 3600),
    minute = Math.floor(((offset % 86400) % 3600) / 60),
    second = Math.floor(((offset % 86400) % 3600) % 60);
  timeToNowDOM.innerHTML =
    day + "天" + hour + "小时" + minute + "分钟" + second + "秒";
  setTimeout(updateTimeStr, 500);
}

setTimeout(updateTimeStr, 500);
</script>


      <div class="back-to-top hidden">
  <span>
    <i class="iconfont icon-60"></i><span></span>%
  </span>
</div>

<script>
const updateIconToTop = percent => {
  let dom = document.querySelector(".back-to-top span span");
  dom.innerText = percent;
  if(percent < 1) {
    document.querySelector(".back-to-top").className = "back-to-top hidden";
  } else {
    document.querySelector(".back-to-top").className = "back-to-top";
  }
}

const handleScoll = () => {
  let isRunning = false;
  return () => {
    if (isRunning) return;
    isRunning = true;
    window.requestAnimationFrame(timestamp => {
      let scrollTop =
          document.documentElement.scrollTop || document.body.scrollTop,
        scrollHeight =
          document.documentElement.scrollHeight ||
          document.body.scrollHeight,
        clientHeight =
          document.documentElement.clientHeight ||
          document.body.clientHeight;
      isRunning = false;
      if (scrollTop <= 1) {
        updateIconToTop(0);
        return;
      }
      if (scrollTop + clientHeight >= scrollHeight) {
        updateIconToTop(100);
      } else {
        updateIconToTop(parseInt(
          100 * scrollTop / (scrollHeight - clientHeight),
          10
        ));
      }
    });
  };
}

const backToTop = () => {
  let scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop,
    delay = 10,
    time = 200;
  if (scrollTop <= 20) {
    document.documentElement.scrollTop = 0;
    document.body.scrollTop = 0;
    return;
  }
  let step = Math.ceil(scrollTop * delay / time);
  let timer = setInterval(() => {
    scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop;
    if (scrollTop - step <= 0) {
      document.documentElement.scrollTop = 0;
      document.body.scrollTop = 0;
      clearInterval(timer);
    } else {
      document.documentElement.scrollTop = scrollTop - step;
      document.body.scrollTop = scrollTop - step;
    }
  }, delay);
}

document.addEventListener("scroll", handleScoll(), false);

document.querySelector(".back-to-top").addEventListener("click", backToTop, false);

</script>

    </div>

    
      <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
<script>
  (() => {
    const mathjaxConfig = {
      showProcessingMessages: false, //关闭js加载过程信息
      messageStyle: "none", //不显示信息
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
        displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
        skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
      },
      "HTML-CSS": {
        availableFonts: ["STIX", "TeX"], //可选字体
        showMathMenu: false //关闭右击菜单显示
      }
    }

    let mathjaxInterval = setInterval(() => {
      if(!window.MathJax){
        return;
      }
      window.MathJax.Hub.Config(mathjaxConfig)
      window.MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.getElementById('app')])

      clearInterval(mathjaxInterval)
    }, 10)    
  })()
</script>
    

    <script src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script>
<script async>
  let fancyTimer = setInterval(function(){
    if(!window.$){
      return;
    }
    $(document).ready(function() {
      $(".post img").each(function () {
        if($(this).parent().get(0).tagName.toLowerCase() === "a") {
          return;
        }
        // $(this).attr("data-fancybox", "gallery"); // if you add 'data-fancybox', img will display after showed
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "gallery");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      });
      
      clearInterval(fancyTimer);
    });
  }, 10);
</script>

    
  </body>

</html>
